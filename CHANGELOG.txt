EASY BATCH FRAMEWORK CHANGELOG
==============================
http://www.easybatch.org

Changes in version 4.2.0 (2016-09-25)
-------------------------------------

Features

* issue #205 : Add BeanPropertiesPreparedStatementProvider
* issue #208 : add StandardErrorRecordWriter
* issue #214 : Replace "strict mode" parameter with "error threshold"

Bug Fixes

* issue #202 : Incorrect duration when unable to open the record reader
* issue #203 : Incorrect data source when unable to open the record reader
* issue #206 : Incoherent log message when filtering a batch of records
* issue #207 : Incorrect log message when unable to process a batch of records
* issue #210 : java.rmi.UnmarshalException when using the JobMonitorProxy

Deprecations

* issue #212 : "skip" parameter is redundant
* issue #213 : "silent mode" parameter is redundant
* issue #215 : "limit" parameter is redundant
* issue #216 : Job timeout should be handled by the executor
* issue #217 : Inappropriate "call" method in JobBuilder API
* issue #218 : Rename "jmx mode" parameter into "jmx monitoring" deprecation
* issue #219 : deprecate the ComputationalRecordProcessor API

Changes in version 4.1.0 (2016-07-30)
-------------------------------------

Features

* issue #123: Add support for MS Excel format using Apache POI
* issue #168: Add last error in job report
* issue #171: Add support to trim whitespace for `FixedLengthRecordMapper`
* issue #175: Add retry on failure for the record reader
* issue #187: Add host name to job report
* issue #196: Add JMX monitoring push notifications
* issue #198: `BlockingQueueRecordReader` should be configurable with the number of poison records received

Fixed bugs

* Issue #169: When Reader fails Job Listeners are not being invoked
* Issue #191: `NumberFormatException` in `IntegerTypeConverter`

Enhancements and API changes

* issue #186: inconsistent `BlockingQueue` record reader/writer APIs
* issue #190: `JobMonitor` should not be public
* issue #193: Data source name of blocking queue is too long
* issue #194: Improve JUL log record format
* issue #195: Not appropriate `JobReportMerger` and `DefaultJobReportMerger` API package
* issue #199: Add utility method to check if a record is a poison record

Changes in version 4.0.0 (2015-11-07)
-------------------------------------

Features:

* Add PayloadExtractor (issue #162)
* Add JmsPoisonMessageBroadcaster (issue #161)
* Add JmsRecord dispatchers (issue #158)
* Add BatchProcessor (issue #157)
* Add BatchValidator (issue #156)
* Add BatchFilter (issue #153)
* Add BatchMapper (issue #152)
* Add BatchMarshaller (issue #151)
* Add JpaBatchWriter (issue #131)
* Add HibernateBatchWriter (issue #130)
* Add JMS queue/connection listeners (issue #147)
* Add FAILED job status (issue #144)
* Add JobExecutor (issue #143)
* Add RecordProcessingTimeListener (issue #133)
* Add "timeout" parameter (issue #132)
* Add "keep alive" parameter (issue #129)
* Add EmptyRecordFilter (issue #120)
* Add method to register a record dispatcher in the job builder API (issue #159)
* Add method to register a record marshaller in the job builder API (issue #138)
* Add BlockingQueueRecordWriter (issue #135)

Enhancements:

* Redesign the workflow into a consistent pipeline (issue #136)
* Improve workflow consistency (issue #160)
* Migrate to Java 7 (issue #148)
* Use varargs instead of arrays in mapper constructor (issue #150)
* Introduce JobParameters and JobMetrics (issue #142)
* Unify Handlers and Listeners (issue #137)

* Rename JmsRecordWriter to JmsQueueRecordWriter (issue #155)
* Rename MultiRecord to Batch (issue #154)
* Rename JmsRecordReader to JmsQueueRecordReader (issue #149)
* Rename CliRecordReader to StandardInputRecordReader (issue #146)
* Rename QueueRecordReader to BlockingQueueRecordReader (issue #145)
* Rename Engine to Job (issue #141)

* Remove ListRecordReader, deprecated in V3.0 (issue #140)
* Remove commit-interval from transaction listeners (issue #139)
* Remove redundant generic type declaration in ObjectMapper (issue #134)

Bug fixes:

* Fixed issue #126: ApacheCommonsCsv prints a header for each line
* Fixed issue #125: Skipped records are not calculated in the merged report

Changes in version 3.1.0 (2015-08-09)
-------------------------------------

Features:

* Added the "skip" parameter (issue #77)
* Added the "limit" parameter (issue #78)
* Added record writers: OutputStream (issue #79), JPA (issue #80), MongoDB (issue #82), JDBC (issue #83), JMS (issue #85), Collection (issue #106), String (issue #109)
* Added Hibernate support: new HibernateRecordReader and HibernateRecordWriter APIs (issue #81)
* Added XmlRecordCompactor and JsonRecordCompactor to flatten hierarchical data (issue #86)
* Added IterableRecordReader and deprecated ListRecordReader (issue #88)
* Added RecordCollector (issue #89)
* Added record marshallers: Xstream (issue #94), Xml (issue #95), Delimited (issue #96), FixedLength (issue #97), ApacheCommonCsv (issue #98), Gson (issue #99), Jackson (issue #100)
* Added multi-record readers to support chunk processing (issue #87): Flat files, Iterable, String, File, Xml, Json, JPA, Apache Common Csv, Hibernate, MongoDB
* Added multi-record writers: Collection (issue #110), File (issue #111), OutputStream (issue #112), StandardOutput (issue #113), String (issue #115), JDBC (issue #116)
* Added GenericMultiRecordMapper (issue #101)
* Added RecordFieldExtractor (PR #117)
* Added lineSeparator parameter to OutputStreamRecordWriter (PR #118)

Enhancements:

* Implemented improvement #91: Add system properties to the execution report
* Implemented improvement #93: Make the JpaRecordReader stream records
* Implemented improvement #103: Make the ObjectMapper properly handle empty values
* Implemented improvement #119: Use CSVFormat null recordSeparator to skip new line creation

Changes in version 3.0.3 (2015-07-01)
-------------------------------------

Enhancements:

* Implemented improvement #69: Step event listeners should make it possible to modify the record's payload
* Implemented improvement #72: Scheduling repeat interval should be in seconds
* Implemented improvement #73: The FileRecordReader should be recursive

Bug fixes:

* Fixed issue #67: Problem with Xml special characters
* Fixed issue #68: Invalid XML when reading XML content with custom namespace
* Fixed issue #70: Incorrect statistic percent in report when total records = 0
* Fixed issue #71: Stopping a batch job scheduler affects other schedulers
* Fixed issue #74: Report statistics percents are not correctly rounded
* Fixed issue #75: JMS poison records are ignored
* Fixed issue #76: Runtime exceptions thrown by custom listeners are not handled properly

Changes in version 3.0.2 (2015-06-10)
-------------------------------------

Enhancements:

* Implemented improvement #55: Do not calculate the total records number upfront by default
* Implemented improvement #59: The fetch size of jdbc statement should be configurable in the JdbcRecordReader
* Implemented improvement #60: Change the type of ResultSet to TYPE_FORWARD_ONLY in the JdbcRecordReader
* Implemented improvement #63: Register multiple record validators

Bug fixes:

* Fixed issue #53: Incorrect record number with large data set
* Fixed issue #54: Reporting can lead to an OutOfMemory error with large data sets
* Fixed issue #56: The negate behavior of RecordFilter does not work
* Fixed issue #57: NPE in ObjectMapper when there is no setter for a given field
* Fixed issue #58: Incorrect start time in report
* Fixed issue #61: The XmlRecordReader does not support custom namespace declaration
* Fixed issue #62: Unable to monitor parallel engines
* Fixed issue #65: Error in Multiple Jobs Scheduling

Changes in version 3.0.1 (2015-05-03)
-------------------------------------

Enhancements:

* Implemented improvement #49: Provide custom mapping strategy for the JdbcRecordMapper

Bug fixes:

* Fixed issue #46: Unable to run multiple BatchSchedulers
* Fixed issue #47: Error reading XML File
* Fixed issue #48: Error reading Json data source
* Fixed issue #50: Error in mapping a delimited record
* Fixed issue #51: Error while parsing embedded object/array in a Json stream
* Fixed issue #52: Unable to register a custom type converter

Changes in version 3.0.0 (2015-03-01)
-------------------------------------

Features:

* Introduced the processing pipeline in the framework's core
* Introduced the filter chain in the framework's core
* Added pre/post processing before/after each step of the workflow: PR #35
* Added custom ignored/rejected/error record handlers: PR #34
* Added support for reading data using JPA
* Added support for reading data from a JMS queue
* Added support for reading data from MongoDB
* Added support for reading data from a JSON data source
* Added integration module with OpenCSV and Apache commons CSV for flat file parsing
* Added integration module with Xstream for Xml -> Object mapping
* Added integration module with Jackson and Gson for Json -> Object mapping
* Added integration module with Spring JDBC for ResultSet -> Object mapping
* Added the AbstractRecordDispatcher API with 4 convenient implementations for more efficient parallel processing
* Added the QueueRecordReader API to read data from a BlockingQueue
* Added the ListRecordReader API to read data from a List
* Added Status enumeration to report batch execution final status
* Added the HeaderRecordFilter, PoisonRecordFilter and GrepFilter utility filters
* Added the GenericRecord API
* Added convenient PoisonRecordFilter to filter poison records
* Added a maven archetype to generate a pre-configured Easy Batch project

Enhancements:

* Refactored the Builder API with more meaningful method names
* Renamed the ReportAggregator interface with ReportMerger
* Removed 'EasyBatch' prefix from all public APIs
* Improved test coverage
* Improved tutorials
* Updated documentation and Javadoc

Bug fixes:

* Fixed issue #32 : Missing placeHolder value when generating an EasyBatchReport

Changes in version 2.2.0 (2014-06-08)
-------------------------------------

* Changed website URL to http://www.easybatch.org
* Changed base package form io.github.benas.easybatch to org.easybatch
* Changed maven group id to org.easybatch
* Moved benchmark classes to a dedicated module easybatch-bench which now uses JMH for microbenchmarks
* Fixed issue #29 : EasyBatchReport problem while processing large volume files
* Fixed issue #30 : fix java.io.FileNotFoundException when running the Spring tutorial
* Fixed issue #31 : Add the possibility to customise the JAXB unmarshaller in XmlRecordMapper
* Added tutorial about processing JSON data source
* Updated documentation and Javadoc

Changes in version 2.1.3 (2014-02-23)
-------------------------------------

* Added strict mode to abort execution on first error
* Added EasyBatchReportsAggregator API to merge partial reports
* Added JMS tutorial
* Fixed issue#27: ObjectMapper throws a NPE when using JDBC column aliases
* Fixed issue#28: ObjectMapper throws a NPE when there is no Pojo field corresponding to a given database column
* Changed FlatFileRecordReader constructor to take a java.io.File object instead of file path for input file
* Changed XmlRecordReader constructor to take a java.io.File object instead of file path for input file
* Changed XmlRecordMapper constructor to take a java.io.File object instead of file path for xsd file
* Moved Spring and Quartz integration modules to a separate directory
* Updated documentation and Javadoc

Changes in version 2.1.2 (2014-02-16)
-------------------------------------

* Added a tutorial with an advanced ETL application
* Added a tutorial with a custom record reader of a master-detail delimited flat file
* Fixed issue#26 : Incorrect record processing time average value
* Fixed issue#25 : A resource leak occurs if a unexpected exception is thrown during batch processing
* Fixed issue#24 : add the possibility to select only some delimited fields to be mapped to domain object
* Fixed a NPE in XmlRecordMapper
* Updated documentation and Javadoc

Changes in version 2.1.1 (2014-02-01)
-------------------------------------

* Added a Spring factory bean to use Easy Batch engine as a Spring bean
* Added a performance benchmark
* Fixed issue#23 : DateTypeConverter always uses the default date format
* Fixed issue#22 : Make DelimitedRecordMapper more intelligent : add convention over configuration to read field names from header record
* Fixed issue#21 : NoOpRecordProcessor throws java.lang.ClassCastException when using a custom POJO
* Fixed issue#20 : Easy Batch Object Mapper does not handle inherited fields
* Fixed issue#19 : Make JdbcRecordMapper more intelligent : add convention over configuration to read field names from the result set meta data
* Fixed issue#18 : Wrong JMX metrics when total records count is undefined
* Fixed issue#17 : show "N/A" instead of "null" for total records count in the JMX console when the total records count is undefined.
* Fixed issue#16 : Easy Batch crashes if an unexpected exception occurs during data validation
* Fixed issue#15 : Easy Batch crashes if an unexpected exception occurs during reading the next data source record
* Fixed issue#14 : Easy Batch crashes if an unexpected exception occurs during opening/closing data source reader
* Fixed issue#13 : Add the possibility to specify the date format for the DateTypeConverter
* Fixed issue#12 : make the BooleanTypeConverter more intelligent
* Merged pull request #11 from nihed/master : Update poms to use dependencyManagement
* Renamed <code>DsvRecordMapper</code> to <code>DelimitedRecordMapper</code>
* Improved code quality by fixing sonar warnings
* Improved Object Mapper implementation : use java.beans.Introspector and java.beans.BeanInfo classes to introspect the target type
* Improved RecordReader API design : make the getTotalRecords method return Long (instead of long) to be able to return null if the total records count cannot be calculated in advance
* Updated documentation and Javadoc

Changes in version 2.1.0 (2014-01-20)
-------------------------------------

* Added a new module to process data from a database using JDBC API
* Added a new module to process data from an xml file using StAX and JAXB APIs
* Added a new API to read data from an in-memory String data source
* Added a new API to read data from the Standard Input
* Added data source name to Easy Batch report
* Added 10 new tutorials about all Easy Batch features (basic, intermediate and advanced)
* Moved record filters to core module
* Fixed issue#10 : reset record numbers when (re)opening the jdbc record reader
* Updated documentation and Javadoc

Changes in version 2.0.0 (2014-01-12)
-------------------------------------

* Renamed the former CB4J framework to Easy Batch which can now handle not only CSV input but also any type of input data
* Added a new Record interface for generic input data type
* Added record filtering feature through the RecordFilter API
* Added new EasyBatchReportFormatter API to format Easy Batch reports to a specific format
* Redesigned validation approach which is now well integrated with the Bean Validation API (JSR303)
* Simplified logging through a single and centralised log file
* Updated documentation and Javadoc

Changes in version 1.4.0 (2013-09-21)
-------------------------------------

* Added BatchResultHolder API to be able to get computation result at the end of batch execution
* Added DefaultRecordMapperImpl class to map records to domain objects based on field names declared in header record
* Added TypeConverter API to extend CB4J's built-in type conversion utilities
* Added a new parameter to abort execution on first record processing error
* Added a new parameter to abort execution on first record mapping exception
* Added a new parameter to enable/disable JMX monitoring feature
* Added two new validators to validate that date value is before/after a given date
* Added two new validators to validate that field field content size has a min/max length
* Fixed issue#5 : CB4J runs indefinitely when an exception occurs during batch finalization step
* Fixed issue#6 : Record number in batch report does not match real record number when skipping header record
* Fixed issue#7 : A non sens warning is reported by CB4J when file encoding is not specified
* Fixed issue#8 : add a log message to inform the user that the engine is about to abort execution on first reject/error
* Fixed issue#9 : CB4J must abort execution on first reject when an unexpected exception occurs during record validation
* Updated record size parameter configuration : record size parameter is now optional and is set to header record size by default
* Updated documentation and Javadoc

Changes in version 1.3.0 (2013-04-21)
-------------------------------------

* Added basic record processing transaction support
* Added new JMX custom clients : command line and graphical asynchronous real time monitors
* Added batch configuration builder
* Updated documentation and Javadoc

Changes in version 1.2.0 (2013-01-13)
-------------------------------------

* Added Fixed-Length Record parsing support (issue #2)
* Added cb4j-quartz module to schedule CB4J batch with Quartz scheduler
* Added a database loader use case using Hibernate : the book library tutorial
* Added Spring use case
* Added BatchReport class to allow clients to get a batch report as execution result
* BatchEngine interface now extends Callable and not Runnable to make it possible to return a result object (BatchReport)
* Merged pull request #4 : regular expression validator review
* Updated documentation and Javadoc

Changes in version 1.1.0 (2012-12-08)
-------------------------------------

* Added parameter to support data qualifier character
* Added parameter to trim whitespaces between fields
* Added parameter to support execution abort on first reject
* Added support for JMX monitoring
* Added a log file for records processed with error
* Fixed reporting issue : CB4J hides the root cause when an exception occurs during record processing
* Fixed CB4J crash if an exception occurs during record validation
* Updated documentation and Javadoc

Changes in version 1.0.2 (2012-12-01)
-------------------------------------

* Added support for loading configuration parameters file from the classpath
* Added support for loading parameters from XML properties file
* Added test cases for record parsing with common CSV delimiters
* Enhanced batch reporter performance by about 15% : use StringBuilder instead of String concatenation
* Record parser and validator now return null instead of empty string if no error occurs
* Renamed parameter input.field.separator to input.field.delimiter
* Updated Java Reflection API performance showcase to execute introspection code only once
* Updated documentation and Javadoc

Changes in version 1.0.1 (2012-11-01)
-------------------------------------

* Fixed IndexOutOfBoundsException in RecordMapper
* Fixed IllegalCharsetNameException in BatchConfiguration
* Fixed CB4J crash if an exception occurs during records processing
* Added RecordProcessingException exception to be thrown if an exception occurs during record processing
* Added DefaultRecordProcessorImpl class to simplify implementation of RecordProcessor interface
* Added date value validation support in DateFieldValidator
* Performance enhancement in DateFieldValidator
* Renamed parameter input.record.separator to input.field.separator
* Added FAQ section in documentation
* Fixed typos in documentation
* Updated Javadoc

Changes in version 1.0.0 (2012-10-14)
-------------------------------------

* Initial core API and Implementation
* Common data type validators
